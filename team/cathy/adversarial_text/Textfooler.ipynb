{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Textfooler.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyM8GnG4YSxFq6aGtiR17IgD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pw_k80aK91mp","executionInfo":{"status":"ok","timestamp":1620143616521,"user_tz":240,"elapsed":24744,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"b262cfa1-276e-4fca-f8bd-7604173b0112"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_CRN52SP96iu","executionInfo":{"status":"ok","timestamp":1620143617124,"user_tz":240,"elapsed":12511,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"9594f315-6db3-4c2d-df4c-f49c3e2d39a5"},"source":["%cd /content/gdrive/MyDrive/colab/TextFooler/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/colab/TextFooler\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"sJCLvyxA-R40","executionInfo":{"status":"ok","timestamp":1620143788155,"user_tz":240,"elapsed":183214,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"a020d03b-d61d-4c07-da66-532cfbade919"},"source":["!pip install -r requirements.txt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting absl-py==0.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n","\u001b[K     |████████████████████████████████| 112kB 7.0MB/s \n","\u001b[?25hRequirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.8.1)\n","Collecting beautifulsoup4==4.9.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/25/ff030e2437265616a1e9b25ccc864e0371a0bc3adb7c5a404fd661c6f4f6/beautifulsoup4-4.9.1-py3-none-any.whl (115kB)\n","\u001b[K     |████████████████████████████████| 122kB 14.3MB/s \n","\u001b[?25hCollecting boto3==1.14.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/ef/ef2798db9f86f2910361cf9d5db4a8c7d55a1ecf193d50598e7416377262/boto3-1.14.7-py2.py3-none-any.whl (128kB)\n","\u001b[K     |████████████████████████████████| 133kB 21.9MB/s \n","\u001b[?25hCollecting botocore==1.17.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/32/0d91f8820844e8c4456e755f40ab7ff2e9c46e00e3795cd64b88653204d2/botocore-1.17.7-py2.py3-none-any.whl (6.3MB)\n","\u001b[K     |████████████████████████████████| 6.3MB 13.4MB/s \n","\u001b[?25hCollecting certifi==2020.4.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/99/def511020aa8f663d4a2cfaa38467539e864799289ff354569e339e375b1/certifi-2020.4.5.2-py2.py3-none-any.whl (157kB)\n","\u001b[K     |████████████████████████████████| 163kB 46.9MB/s \n","\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (3.0.4)\n","Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n","Collecting docutils==0.15.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n","\u001b[K     |████████████████████████████████| 552kB 66.6MB/s \n","\u001b[?25hCollecting feedparser==5.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n","\u001b[K     |████████████████████████████████| 194kB 68.8MB/s \n","\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.3.3)\n","Collecting grpcio==1.29.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/ca/5e135298d1c033dffa25e9d34b8f848d000aa2bc9c6001768b289e51295e/grpcio-1.29.0-cp37-cp37m-manylinux2010_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 64.1MB/s \n","\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.10.0)\n","Collecting idna==2.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n","\u001b[?25hCollecting importlib-metadata==1.6.1\n","  Downloading https://files.pythonhosted.org/packages/98/13/a1d703ec396ade42c1d33df0e1cb691a28b7c08b336a5683912c87e04cd7/importlib_metadata-1.6.1-py2.py3-none-any.whl\n","Collecting jmespath==0.10.0\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting joblib==0.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/a6/d1a816b89aa1e9e96bcb298eb1ee1854f21662ebc6d55ffa3d7b3b50122b/joblib-0.15.1-py3-none-any.whl (298kB)\n","\u001b[K     |████████████████████████████████| 307kB 68.8MB/s \n","\u001b[?25hCollecting Keras-Applications==1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n","\u001b[?25hRequirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (1.1.2)\n","Collecting lxml==4.5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/39/0b5d76e64681243db516491bc449eff847d2708b465b60465b31ca13522e/lxml-4.5.1-cp37-cp37m-manylinux1_x86_64.whl (5.5MB)\n","\u001b[K     |████████████████████████████████| 5.5MB 62.8MB/s \n","\u001b[?25hCollecting Markdown==3.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88kB)\n","\u001b[K     |████████████████████████████████| 92kB 13.7MB/s \n","\u001b[?25hCollecting nltk==3.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 73.7MB/s \n","\u001b[?25hCollecting numpy==1.19.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/31/e2c3eda7afe7dab08e1f24767b8e38ff2f30dc82bd74aa3a5324c550366a/numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl (14.6MB)\n","\u001b[K     |████████████████████████████████| 14.6MB 58.4MB/s \n","\u001b[?25hCollecting protobuf==3.12.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/63/2c505711827446bfdb544e7bcc0d7694b115d22d56175902a2581fe1172a/protobuf-3.12.2-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 55.2MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 25)) (2.8.1)\n","Collecting python-docx==0.8.10\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/83/c66a1934ed5ed8ab1dbb9931f1779079f8bca0f6bbc5793c06c4b5e7d671/python-docx-0.8.10.tar.gz (5.5MB)\n","\u001b[K     |████████████████████████████████| 5.5MB 70.9MB/s \n","\u001b[?25hCollecting regex==2020.6.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/60/cd50cc641bc3199bce3d37b3d240c20af9447ee06c8c283def56d7914232/regex-2020.6.8-cp37-cp37m-manylinux2010_x86_64.whl (661kB)\n","\u001b[K     |████████████████████████████████| 665kB 57.2MB/s \n","\u001b[?25hCollecting requests==2.24.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n","\u001b[K     |████████████████████████████████| 71kB 11.5MB/s \n","\u001b[?25hCollecting s3transfer==0.3.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 11.1MB/s \n","\u001b[?25hRequirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 30)) (1.15.0)\n","Collecting soupsieve==2.0.1\n","  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\n","Collecting tensorboard==1.12.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 54.8MB/s \n","\u001b[?25hCollecting tensorflow-gpu==1.13.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/65/8dc8fc4a263a24f7ad935b72ad35e72ba381cb9e175b6a5fe086c85f17a7/tensorflow_gpu-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (345.0MB)\n","\u001b[K     |████████████████████████████████| 345.0MB 38kB/s \n","\u001b[?25hCollecting tensorflow-hub==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/0e/a91780d07592b1abf9c91344ce459472cc19db3b67fdf3a61dca6ebb2f5c/tensorflow_hub-0.7.0-py2.py3-none-any.whl (89kB)\n","\u001b[K     |████████████████████████████████| 92kB 13.0MB/s \n","\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 35)) (1.1.0)\n","Collecting torch==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/65/5248be50c55ab7429dd5c11f5e2f9f5865606b80e854ca63139ad1a584f2/torch-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (748.9MB)\n","\u001b[K     |████████████████████████████████| 748.9MB 24kB/s \n","\u001b[?25hCollecting tqdm==4.46.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/76/4697ce203a3d42b2ead61127b35e5fcc26bba9a35c03b32a2bd342a4c869/tqdm-4.46.1-py2.py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.5MB/s \n","\u001b[?25hCollecting urllib3==1.25.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl (126kB)\n","\u001b[K     |████████████████████████████████| 133kB 58.2MB/s \n","\u001b[?25hRequirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 39)) (1.0.1)\n","Collecting zipp==3.1.0\n","  Downloading https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf==3.12.2->-r requirements.txt (line 24)) (56.0.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.12.2->-r requirements.txt (line 32)) (0.36.2)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 68.6MB/s \n","\u001b[?25hCollecting mock>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n","Building wheels for collected packages: absl-py, feedparser, nltk, python-docx\n","  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for absl-py: filename=absl_py-0.9.0-cp37-none-any.whl size=121931 sha256=963a7c754df72f5bfeff97645b269c16f97cc36e5a9a39026724cbe682729f0e\n","  Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n","  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for feedparser: filename=feedparser-5.2.1-cp37-none-any.whl size=44940 sha256=2c46340b2d3784a2226c347e38ddaec07ea7c0f59a5e5f3a7e71f7ebdc109e6d\n","  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-cp37-none-any.whl size=1434676 sha256=502381daa9eebd76275bf81f85cf054c0f7e4290a6fb5a110c713f342e8dbc66\n","  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n","  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-docx: filename=python_docx-0.8.10-cp37-none-any.whl size=184491 sha256=a6947e7410dd5ce0690537ead51e152505d3f4f6f744e0dc4464f7081f9ca455\n","  Stored in directory: /root/.cache/pip/wheels/18/0b/a0/1dd62ff812c857c9e487f27d80d53d2b40531bec1acecfa47b\n","Successfully built absl-py feedparser nltk python-docx\n","\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement absl-py~=0.10, but you'll have absl-py 0.9.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.29.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.19.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.12.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-gpu 1.13.1 has requirement tensorboard<1.14.0,>=1.13.0, but you'll have tensorboard 1.12.2 which is incompatible.\u001b[0m\n","Installing collected packages: absl-py, soupsieve, beautifulsoup4, docutils, jmespath, urllib3, botocore, s3transfer, boto3, certifi, feedparser, grpcio, idna, zipp, importlib-metadata, joblib, numpy, Keras-Applications, lxml, Markdown, regex, tqdm, nltk, protobuf, python-docx, requests, tensorboard, mock, tensorflow-estimator, tensorflow-gpu, tensorflow-hub, torch\n","  Found existing installation: absl-py 0.12.0\n","    Uninstalling absl-py-0.12.0:\n","      Successfully uninstalled absl-py-0.12.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","  Found existing installation: docutils 0.17\n","    Uninstalling docutils-0.17:\n","      Successfully uninstalled docutils-0.17\n","  Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Found existing installation: certifi 2020.12.5\n","    Uninstalling certifi-2020.12.5:\n","      Successfully uninstalled certifi-2020.12.5\n","  Found existing installation: grpcio 1.32.0\n","    Uninstalling grpcio-1.32.0:\n","      Successfully uninstalled grpcio-1.32.0\n","  Found existing installation: idna 2.10\n","    Uninstalling idna-2.10:\n","      Successfully uninstalled idna-2.10\n","  Found existing installation: zipp 3.4.1\n","    Uninstalling zipp-3.4.1:\n","      Successfully uninstalled zipp-3.4.1\n","  Found existing installation: importlib-metadata 3.10.1\n","    Uninstalling importlib-metadata-3.10.1:\n","      Successfully uninstalled importlib-metadata-3.10.1\n","  Found existing installation: joblib 1.0.1\n","    Uninstalling joblib-1.0.1:\n","      Successfully uninstalled joblib-1.0.1\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Found existing installation: lxml 4.2.6\n","    Uninstalling lxml-4.2.6:\n","      Successfully uninstalled lxml-4.2.6\n","  Found existing installation: Markdown 3.3.4\n","    Uninstalling Markdown-3.3.4:\n","      Successfully uninstalled Markdown-3.3.4\n","  Found existing installation: regex 2019.12.20\n","    Uninstalling regex-2019.12.20:\n","      Successfully uninstalled regex-2019.12.20\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Found existing installation: protobuf 3.12.4\n","    Uninstalling protobuf-3.12.4:\n","      Successfully uninstalled protobuf-3.12.4\n","  Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorflow-hub 0.12.0\n","    Uninstalling tensorflow-hub-0.12.0:\n","      Successfully uninstalled tensorflow-hub-0.12.0\n","  Found existing installation: torch 1.8.1+cu101\n","    Uninstalling torch-1.8.1+cu101:\n","      Successfully uninstalled torch-1.8.1+cu101\n","Successfully installed Keras-Applications-1.0.8 Markdown-3.2.2 absl-py-0.9.0 beautifulsoup4-4.9.1 boto3-1.14.7 botocore-1.17.7 certifi-2020.4.5.2 docutils-0.15.2 feedparser-5.2.1 grpcio-1.29.0 idna-2.9 importlib-metadata-1.6.1 jmespath-0.10.0 joblib-0.15.1 lxml-4.5.1 mock-4.0.3 nltk-3.5 numpy-1.19.0 protobuf-3.12.2 python-docx-0.8.10 regex-2020.6.8 requests-2.24.0 s3transfer-0.3.3 soupsieve-2.0.1 tensorboard-1.12.2 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1 tensorflow-hub-0.7.0 torch-1.2.0 tqdm-4.46.1 urllib3-1.25.9 zipp-3.1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQ2gFUIZ-T2W","executionInfo":{"status":"ok","timestamp":1620143788156,"user_tz":240,"elapsed":179869,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"c382ecda-c04e-433b-a55e-87f225fcc0f5"},"source":["%cd ESIM"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/colab/TextFooler/ESIM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8jlDvgsBQ4k","executionInfo":{"status":"ok","timestamp":1620143795814,"user_tz":240,"elapsed":187217,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"2c8ca472-0d98-40fe-f448-66cc42c5efae"},"source":["!python setup.py install"],"execution_count":5,"outputs":[{"output_type":"stream","text":["running install\n","running bdist_egg\n","running egg_info\n","writing ESIM.egg-info/PKG-INFO\n","writing dependency_links to ESIM.egg-info/dependency_links.txt\n","writing requirements to ESIM.egg-info/requires.txt\n","writing top-level names to ESIM.egg-info/top_level.txt\n","writing manifest file 'ESIM.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/esim\n","copying build/lib/esim/__init__.py -> build/bdist.linux-x86_64/egg/esim\n","copying build/lib/esim/utils.py -> build/bdist.linux-x86_64/egg/esim\n","copying build/lib/esim/model.py -> build/bdist.linux-x86_64/egg/esim\n","copying build/lib/esim/data.py -> build/bdist.linux-x86_64/egg/esim\n","copying build/lib/esim/layers.py -> build/bdist.linux-x86_64/egg/esim\n","byte-compiling build/bdist.linux-x86_64/egg/esim/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/esim/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/esim/model.py to model.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/esim/data.py to data.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/esim/layers.py to layers.cpython-37.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying ESIM.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying ESIM.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying ESIM.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying ESIM.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying ESIM.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating 'dist/ESIM-1.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing ESIM-1.0-py3.7.egg\n","Copying ESIM-1.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n","Adding ESIM 1.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/ESIM-1.0-py3.7.egg\n","Processing dependencies for ESIM==1.0\n","Searching for torch==1.2.0\n","Best match: torch 1.2.0\n","Adding torch 1.2.0 to easy-install.pth file\n","Installing convert-caffe2-to-onnx script to /usr/local/bin\n","Installing convert-onnx-to-caffe2 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for tqdm==4.46.1\n","Best match: tqdm 4.46.1\n","Adding tqdm 4.46.1 to easy-install.pth file\n","Installing tqdm script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for matplotlib==3.2.2\n","Best match: matplotlib 3.2.2\n","Adding matplotlib 3.2.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for nltk==3.5\n","Best match: nltk 3.5\n","Adding nltk 3.5 to easy-install.pth file\n","Installing nltk script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for numpy==1.19.0\n","Best match: numpy 1.19.0\n","Adding numpy 1.19.0 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.7 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for python-dateutil==2.8.1\n","Best match: python-dateutil 2.8.1\n","Adding python-dateutil 2.8.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for cycler==0.10.0\n","Best match: cycler 0.10.0\n","Adding cycler 0.10.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for kiwisolver==1.3.1\n","Best match: kiwisolver 1.3.1\n","Adding kiwisolver 1.3.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pyparsing==2.4.7\n","Best match: pyparsing 2.4.7\n","Adding pyparsing 2.4.7 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for regex==2020.6.8\n","Best match: regex 2020.6.8\n","Adding regex 2020.6.8 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for joblib==0.15.1\n","Best match: joblib 0.15.1\n","Adding joblib 0.15.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for click==7.1.2\n","Best match: click 7.1.2\n","Adding click 7.1.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for six==1.15.0\n","Best match: six 1.15.0\n","Adding six 1.15.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Finished processing dependencies for ESIM==1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGxafz6OBXrZ","executionInfo":{"status":"ok","timestamp":1620143795815,"user_tz":240,"elapsed":186323,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"61877fb8-4eac-4285-ff10-8f3ff7576da1"},"source":["%cd .."],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/colab/TextFooler\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNoXVgZHBg-3","executionInfo":{"status":"ok","timestamp":1620143811915,"user_tz":240,"elapsed":201840,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"5ef827a4-2442-4435-bb52-246453bdf1a3"},"source":["!pip install pattern"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting pattern\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/07/b0e61b6c818ed4b6145fe01d1c341223aa6cfbc3928538ad1f2b890924a3/Pattern-3.6.0.tar.gz (22.2MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 80.2MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pattern) (0.16.0)\n","Collecting backports.csv\n","  Downloading https://files.pythonhosted.org/packages/8e/26/a6bd68f13e0f38fbb643d6e497fc3462be83a0b6c4d43425c78bb51a7291/backports.csv-1.0.7-py2.py3-none-any.whl\n","Collecting mysqlclient\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/df/59cd2fa5e48d0804d213bdcb1acb4d08c403b61c7ff7ed4dd4a6a2deb3f7/mysqlclient-2.0.3.tar.gz (88kB)\n","\u001b[K     |████████████████████████████████| 92kB 12.7MB/s \n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pattern) (4.9.1)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pattern) (4.5.1)\n","Requirement already satisfied: feedparser in /usr/local/lib/python3.7/dist-packages (from pattern) (5.2.1)\n","Collecting pdfminer.six\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/f3/4fec7dabe8802ebec46141345bf714cd1fc7d93cb74ddde917e4b6d97d88/pdfminer.six-20201018-py3-none-any.whl (5.6MB)\n","\u001b[K     |████████████████████████████████| 5.6MB 51.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.19.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pattern) (3.5)\n","Requirement already satisfied: python-docx in /usr/local/lib/python3.7/dist-packages (from pattern) (0.8.10)\n","Collecting cherrypy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/f9/e11f893dcabe6bc222a1442bf5e14f0322a2d363c92910ed41947078a35a/CherryPy-18.6.0-py2.py3-none-any.whl (419kB)\n","\u001b[K     |████████████████████████████████| 419kB 54.4MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pattern) (2.24.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4->pattern) (2.0.1)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern) (2.3.0)\n","Requirement already satisfied: chardet; python_version > \"3.0\" in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern) (3.0.4)\n","Collecting cryptography\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 58.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (4.46.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (0.15.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (7.1.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (2020.6.8)\n","Collecting zc.lockfile\n","  Downloading https://files.pythonhosted.org/packages/6c/2a/268389776288f0f26c7272c70c36c96dcc0bdb88ab6216ea18e19df1fadd/zc.lockfile-2.0-py2.py3-none-any.whl\n","Collecting portend>=2.1.1\n","  Downloading https://files.pythonhosted.org/packages/b8/a1/fd29409cced540facdd29abb986d988cb1f22c8170d10022ea73af77fa55/portend-2.7.1-py3-none-any.whl\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern) (8.7.0)\n","Collecting cheroot>=8.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/95/86fe6480af78fea7b0e7e1bf02e6acd4cb9e561ea200bd6d6e1398fe5426/cheroot-8.5.2-py2.py3-none-any.whl (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 14.7MB/s \n","\u001b[?25hCollecting jaraco.collections\n","  Downloading https://files.pythonhosted.org/packages/d5/1a/a0d6861d2aca6df92643c755966c8a60e40353e4c5e7a5c2f4e5ed733817/jaraco.collections-3.3.0-py3-none-any.whl\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2020.4.5.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (1.25.9)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->pattern) (1.14.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile->cherrypy->pattern) (56.0.0)\n","Collecting tempora>=1.8\n","  Downloading https://files.pythonhosted.org/packages/44/83/4d5c3de53bbc463f30ab6764e27bc2e8ed9b59736e8b40d95403ff802008/tempora-4.0.2-py3-none-any.whl\n","Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.15.0)\n","Collecting jaraco.functools\n","  Downloading https://files.pythonhosted.org/packages/b5/da/e51e7b58c8fe132990edd1e3ef25bcd9801eb7f91d0f642ac7f8d97e4a36/jaraco.functools-3.3.0-py3-none-any.whl\n","Collecting jaraco.classes\n","  Downloading https://files.pythonhosted.org/packages/b8/74/bee5fc11594974746535117546404678fc7b899476e769c3c55bc0cfaa02/jaraco.classes-3.2.1-py3-none-any.whl\n","Collecting jaraco.text\n","  Downloading https://files.pythonhosted.org/packages/c1/74/2a3c4835c079df16db8a9c50263eebb0125849fee5b16de353a059b7545d/jaraco.text-3.5.0-py3-none-any.whl\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->pattern) (2.20)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2018.9)\n","Building wheels for collected packages: pattern, mysqlclient\n","  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pattern: filename=Pattern-3.6-cp37-none-any.whl size=22332724 sha256=0cbc08c618cc900e68ee7f703d0786b11626da1d1a3212fbef15a718f4797012\n","  Stored in directory: /root/.cache/pip/wheels/dc/9a/0e/5fb1a603ed4e3aa8722a88e9cf4a82da7d1b63e3d2cc34bee5\n","  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mysqlclient: filename=mysqlclient-2.0.3-cp37-cp37m-linux_x86_64.whl size=100089 sha256=cd106fe21720f6e39d1522b9d8ea257a28bc0a62749f7b924c1590d5b037c3f7\n","  Stored in directory: /root/.cache/pip/wheels/75/ca/e8/ad4e7ce3df18bcd91c7d84dd28c7c08db491a2a2360efed363\n","Successfully built pattern mysqlclient\n","Installing collected packages: backports.csv, mysqlclient, cryptography, pdfminer.six, zc.lockfile, jaraco.functools, tempora, portend, cheroot, jaraco.classes, jaraco.text, jaraco.collections, cherrypy, pattern\n","Successfully installed backports.csv-1.0.7 cheroot-8.5.2 cherrypy-18.6.0 cryptography-3.4.7 jaraco.classes-3.2.1 jaraco.collections-3.3.0 jaraco.functools-3.3.0 jaraco.text-3.5.0 mysqlclient-2.0.3 pattern-3.6 pdfminer.six-20201018 portend-2.7.1 tempora-4.0.2 zc.lockfile-2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yPdTpo1B9F4","executionInfo":{"status":"ok","timestamp":1620143824091,"user_tz":240,"elapsed":213110,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"c2e2dc57-c72c-46d6-dea8-9463c0acd476"},"source":["!pip uninstall -y tensorflow"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.4.1:\n","  Successfully uninstalled tensorflow-2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Tip3-MHPCRcG","executionInfo":{"status":"ok","timestamp":1620143881953,"user_tz":240,"elapsed":270601,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"efd48dc7-108f-491d-c0ed-6373472e78f0"},"source":["!pip install \"tf-nightly\""],"execution_count":9,"outputs":[{"output_type":"stream","text":["Collecting tf-nightly\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/62/30ebbba3b4b016b299560ab7c80c57e2453dce422ee75006a1228f4d0524/tf_nightly-2.6.0.dev20210504-cp37-cp37m-manylinux2010_x86_64.whl (452.9MB)\n","\u001b[K     |████████████████████████████████| 452.9MB 20kB/s \n","\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n","Collecting grpcio<2.0,>=1.37.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d8/1bfe90cc49c166dd2ec1be46fa4830c254ce702004a110830c74ec1df0c0/grpcio-1.37.1-cp37-cp37m-manylinux2014_x86_64.whl (4.2MB)\n","\u001b[K     |████████████████████████████████| 4.2MB 60.2MB/s \n","\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.12.2)\n","Collecting gast==0.4.0\n","  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n","Collecting tb-nightly~=2.6.0.a\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/29/50a2e1ca2d0d5eda54b82d3fd9bb1cfbd8d73fff3b6b862e610959ae8f8b/tb_nightly-2.6.0a20210504-py3-none-any.whl (5.9MB)\n","\u001b[K     |████████████████████████████████| 5.9MB 24.8MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n","Collecting absl-py~=0.10\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/c9/ef0fae29182d7a867d203f0eff8296b60da92098cc41db33a434f4be84bf/absl_py-0.12.0-py3-none-any.whl (129kB)\n","\u001b[K     |████████████████████████████████| 133kB 71.0MB/s \n","\u001b[?25hCollecting keras-nightly~=2.6.0.dev\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/e6/78d18d6f9959026ab728ea336e5c27ed13af2cc5b254a37419986d361e3f/keras_nightly-2.6.0.dev2021050400-py2.py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 75.4MB/s \n","\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.36.2)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n","Collecting h5py~=3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n","\u001b[K     |████████████████████████████████| 4.0MB 74.3MB/s \n","\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n","Collecting tf-estimator-nightly~=2.5.0.dev\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/6c/9bf4a6004d18c8e543845d3416e50f36dd09d272161e2fb0db5678132dfd/tf_estimator_nightly-2.5.0.dev2021032601-py2.py3-none-any.whl (462kB)\n","\u001b[K     |████████████████████████████████| 471kB 65.2MB/s \n","\u001b[?25hCollecting numpy~=1.19.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/d6/a6aaa29fea945bc6c61d11f6e0697b325ff7446de5ffd62c2fa02f627048/numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8MB)\n","\u001b[K     |████████████████████████████████| 14.8MB 62.5MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tf-nightly) (56.0.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (2.24.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (1.28.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (1.8.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/63/d92b4bc44261b7396558c054f78acf71468b5628bcb14cdaeb2504ea80d3/tensorboard_data_server-0.6.0-py3-none-manylinux2010_x86_64.whl (3.9MB)\n","\u001b[K     |████████████████████████████████| 3.9MB 58.2MB/s \n","\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (3.2.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (0.4.4)\n","Collecting cached-property; python_version < \"3.8\"\n","  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (1.25.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (2020.4.5.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (4.7.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.6.0.a->tf-nightly) (1.6.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly~=2.6.0.a->tf-nightly) (3.1.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly) (3.1.0)\n","\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n","\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-gpu 1.13.1 has requirement tensorboard<1.14.0,>=1.13.0, but you'll have tensorboard 1.12.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: grpcio, gast, tensorboard-data-server, numpy, absl-py, tb-nightly, keras-nightly, cached-property, h5py, tf-estimator-nightly, tf-nightly\n","  Found existing installation: grpcio 1.29.0\n","    Uninstalling grpcio-1.29.0:\n","      Successfully uninstalled grpcio-1.29.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: numpy 1.19.0\n","    Uninstalling numpy-1.19.0:\n","      Successfully uninstalled numpy-1.19.0\n","  Found existing installation: absl-py 0.9.0\n","    Uninstalling absl-py-0.9.0:\n","      Successfully uninstalled absl-py-0.9.0\n","  Found existing installation: h5py 2.10.0\n","    Uninstalling h5py-2.10.0:\n","      Successfully uninstalled h5py-2.10.0\n","Successfully installed absl-py-0.12.0 cached-property-1.5.2 gast-0.4.0 grpcio-1.37.1 h5py-3.1.0 keras-nightly-2.6.0.dev2021050400 numpy-1.19.5 tb-nightly-2.6.0a20210504 tensorboard-data-server-0.6.0 tf-estimator-nightly-2.5.0.dev2021032601 tf-nightly-2.6.0.dev20210504\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQlr9y-3Dwo1","executionInfo":{"status":"ok","timestamp":1620111693943,"user_tz":240,"elapsed":345221,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"8505badf-d8fb-4081-926f-6314eb1c006e"},"source":["!python comp_cos_sim_mat.py counter-fitted-vectors.txt"],"execution_count":23,"outputs":[{"output_type":"stream","text":["(300, 65713)\n","tcmalloc: large alloc 8636399616 bytes == 0x55cdb79c6000 @  0x7efcd15471e7 0x7efccf10746e 0x7efccf157c7b 0x7efccf158290 0x7efccf1503ea 0x7efccf1f53e4 0x7efccf1f98bd 0x55cda633a2f8 0x7efccf144ef7 0x55cda6337fd7 0x55cda6337de0 0x55cda63abac2 0x55cda63a6b0e 0x55cda633977a 0x55cda63abe50 0x55cda63a6b0e 0x55cda63a6813 0x55cda6470592 0x55cda647090d 0x55cda64707b6 0x55cda6448103 0x55cda6447dac 0x7efcd0331bf7 0x55cda6447c8a\n","^C\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKm-zcUgBezv","executionInfo":{"status":"ok","timestamp":1620143883608,"user_tz":240,"elapsed":268388,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"2313e13c-da99-46bf-8a38-5bb56e8c6a90"},"source":["import nltk\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('universal_tagset')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6QiVVfM-dFw","executionInfo":{"status":"ok","timestamp":1620126527020,"user_tz":240,"elapsed":13655562,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"0a4fc252-6fb1-4526-e487-eae2413ec506"},"source":["#yelp example\n","!python attack_classification.py \\\n","--dataset_path data/yelp \\\n","--target_model bert \\\n","--target_model_path model \\\n","--max_seq_length 256 \\\n","--batch_size 32 \\\n","--counter_fitting_embeddings_path counter-fitted-vectors.txt \\\n","--counter_fitting_cos_sim_path cos_sim_counter_fitting.npy \\\n","--USE_cache_path scratch"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Output directory (adv_results) already exists and is not empty.\n","Data import finished!\n","Building Model...\n","Model built!\n","Building vocab...\n","Building cos sim matrix...\n","Load pre-computed cosine similarity matrix from cos_sim_counter_fitting.npy\n","tcmalloc: large alloc 17272799232 bytes == 0x5619d04f6000 @  0x7effd01641e7 0x7effcdbe446e 0x7effcdc38e7c 0x7effcdc39aaf 0x7effcdcdb470 0x56193819e0e4 0x56193819dde0 0x5619382126f5 0x56193820cb0e 0x56193819f77a 0x56193820e86a 0x56193820cb0e 0x56193819f77a 0x561938211e50 0x56193819f69a 0x56193820da45 0x56193820cb0e 0x56193820c813 0x5619382d6592 0x5619382d690d 0x5619382d67b6 0x5619382ae103 0x5619382addac 0x7effcef4ebf7 0x5619382adc8a\n","Cos sim import finished!\n","2021-05-04 07:25:31.346292: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-05-04 07:25:31.359568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-04 07:25:31.513010: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2021-05-04 07:25:31.530510: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1765] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2021-05-04 07:25:34.322509: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45180160 exceeds 10% of free system memory.\n","2021-05-04 07:25:34.611059: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45180160 exceeds 10% of free system memory.\n","2021-05-04 07:25:34.727456: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45180160 exceeds 10% of free system memory.\n","2021-05-04 07:25:35.319966: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45180160 exceeds 10% of free system memory.\n","2021-05-04 07:25:36.608327: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45180160 exceeds 10% of free system memory.\n","Start attacking!\n","0 samples out of 1000 have been finished!\n","20 samples out of 1000 have been finished!\n","40 samples out of 1000 have been finished!\n","60 samples out of 1000 have been finished!\n","80 samples out of 1000 have been finished!\n","100 samples out of 1000 have been finished!\n","120 samples out of 1000 have been finished!\n","140 samples out of 1000 have been finished!\n","160 samples out of 1000 have been finished!\n","180 samples out of 1000 have been finished!\n","200 samples out of 1000 have been finished!\n","220 samples out of 1000 have been finished!\n","240 samples out of 1000 have been finished!\n","260 samples out of 1000 have been finished!\n","280 samples out of 1000 have been finished!\n","300 samples out of 1000 have been finished!\n","320 samples out of 1000 have been finished!\n","340 samples out of 1000 have been finished!\n","360 samples out of 1000 have been finished!\n","380 samples out of 1000 have been finished!\n","400 samples out of 1000 have been finished!\n","420 samples out of 1000 have been finished!\n","440 samples out of 1000 have been finished!\n","460 samples out of 1000 have been finished!\n","480 samples out of 1000 have been finished!\n","500 samples out of 1000 have been finished!\n","520 samples out of 1000 have been finished!\n","540 samples out of 1000 have been finished!\n","560 samples out of 1000 have been finished!\n","580 samples out of 1000 have been finished!\n","600 samples out of 1000 have been finished!\n","620 samples out of 1000 have been finished!\n","640 samples out of 1000 have been finished!\n","660 samples out of 1000 have been finished!\n","680 samples out of 1000 have been finished!\n","700 samples out of 1000 have been finished!\n","720 samples out of 1000 have been finished!\n","740 samples out of 1000 have been finished!\n","760 samples out of 1000 have been finished!\n","780 samples out of 1000 have been finished!\n","800 samples out of 1000 have been finished!\n","820 samples out of 1000 have been finished!\n","840 samples out of 1000 have been finished!\n","860 samples out of 1000 have been finished!\n","880 samples out of 1000 have been finished!\n","900 samples out of 1000 have been finished!\n","920 samples out of 1000 have been finished!\n","940 samples out of 1000 have been finished!\n","960 samples out of 1000 have been finished!\n","980 samples out of 1000 have been finished!\n","For target model bert: original accuracy: 97.000%, adv accuracy: 6.600%, avg changed rate: 13.879%, num of queries: 827.1\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dzwDTG-z7nYq","executionInfo":{"status":"ok","timestamp":1620149886654,"user_tz":240,"elapsed":6003037,"user":{"displayName":"Cathy Wang","photoUrl":"","userId":"09711870337723513287"}},"outputId":"8460a7f5-770a-4539-bbbe-60a8e7535613"},"source":["!python attack_classification.py \\\n","--dataset_path data/memes \\\n","--target_model bert \\\n","--target_model_path model \\\n","--max_seq_length 256 \\\n","--batch_size 32 \\\n","--counter_fitting_embeddings_path counter-fitted-vectors.txt \\\n","--counter_fitting_cos_sim_path cos_sim_counter_fitting.npy \\\n","--USE_cache_path scratch \\\n","--data_size 9241"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Output directory (adv_results) already exists and is not empty.\n","Data import finished!\n","Building Model...\n","Model built!\n","Building vocab...\n","Building cos sim matrix...\n","Load pre-computed cosine similarity matrix from cos_sim_counter_fitting.npy\n","tcmalloc: large alloc 17272799232 bytes == 0x55d4dbab6000 @  0x7f564027a1e7 0x7f563dcfa46e 0x7f563dd4ee7c 0x7f563dd4faaf 0x7f563ddf1470 0x55d44545d0e4 0x55d44545cde0 0x55d4454d16f5 0x55d4454cbb0e 0x55d44545e77a 0x55d4454cd86a 0x55d4454cbb0e 0x55d44545e77a 0x55d4454d0e50 0x55d44545e69a 0x55d4454cca45 0x55d4454cbb0e 0x55d4454cb813 0x55d445595592 0x55d44559590d 0x55d4455957b6 0x55d44556d103 0x55d44556cdac 0x7f563f064bf7 0x55d44556cc8a\n","Cos sim import finished!\n","2021-05-04 16:02:04.854595: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-05-04 16:02:04.911535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-04 16:02:05.157130: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2021-05-04 16:02:05.178575: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1765] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2021-05-04 16:02:09.512921: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45180160 exceeds 10% of free system memory.\n","2021-05-04 16:02:10.018229: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45180160 exceeds 10% of free system memory.\n","2021-05-04 16:02:10.019779: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45180160 exceeds 10% of free system memory.\n","2021-05-04 16:02:10.516485: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45180160 exceeds 10% of free system memory.\n","2021-05-04 16:02:12.754733: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45180160 exceeds 10% of free system memory.\n","Start attacking!\n","0 samples out of 9241 have been finished!\n","20 samples out of 9241 have been finished!\n","40 samples out of 9241 have been finished!\n","60 samples out of 9241 have been finished!\n","80 samples out of 9241 have been finished!\n","100 samples out of 9241 have been finished!\n","120 samples out of 9241 have been finished!\n","140 samples out of 9241 have been finished!\n","160 samples out of 9241 have been finished!\n","180 samples out of 9241 have been finished!\n","200 samples out of 9241 have been finished!\n","220 samples out of 9241 have been finished!\n","240 samples out of 9241 have been finished!\n","260 samples out of 9241 have been finished!\n","280 samples out of 9241 have been finished!\n","300 samples out of 9241 have been finished!\n","320 samples out of 9241 have been finished!\n","340 samples out of 9241 have been finished!\n","360 samples out of 9241 have been finished!\n","380 samples out of 9241 have been finished!\n","400 samples out of 9241 have been finished!\n","420 samples out of 9241 have been finished!\n","440 samples out of 9241 have been finished!\n","460 samples out of 9241 have been finished!\n","480 samples out of 9241 have been finished!\n","500 samples out of 9241 have been finished!\n","520 samples out of 9241 have been finished!\n","540 samples out of 9241 have been finished!\n","560 samples out of 9241 have been finished!\n","580 samples out of 9241 have been finished!\n","600 samples out of 9241 have been finished!\n","620 samples out of 9241 have been finished!\n","640 samples out of 9241 have been finished!\n","660 samples out of 9241 have been finished!\n","680 samples out of 9241 have been finished!\n","700 samples out of 9241 have been finished!\n","720 samples out of 9241 have been finished!\n","740 samples out of 9241 have been finished!\n","760 samples out of 9241 have been finished!\n","780 samples out of 9241 have been finished!\n","800 samples out of 9241 have been finished!\n","820 samples out of 9241 have been finished!\n","840 samples out of 9241 have been finished!\n","860 samples out of 9241 have been finished!\n","880 samples out of 9241 have been finished!\n","900 samples out of 9241 have been finished!\n","920 samples out of 9241 have been finished!\n","940 samples out of 9241 have been finished!\n","960 samples out of 9241 have been finished!\n","980 samples out of 9241 have been finished!\n","1000 samples out of 9241 have been finished!\n","1020 samples out of 9241 have been finished!\n","1040 samples out of 9241 have been finished!\n","1060 samples out of 9241 have been finished!\n","1080 samples out of 9241 have been finished!\n","1100 samples out of 9241 have been finished!\n","1120 samples out of 9241 have been finished!\n","1140 samples out of 9241 have been finished!\n","1160 samples out of 9241 have been finished!\n","1180 samples out of 9241 have been finished!\n","1200 samples out of 9241 have been finished!\n","1220 samples out of 9241 have been finished!\n","1240 samples out of 9241 have been finished!\n","1260 samples out of 9241 have been finished!\n","1280 samples out of 9241 have been finished!\n","1300 samples out of 9241 have been finished!\n","1320 samples out of 9241 have been finished!\n","1340 samples out of 9241 have been finished!\n","1360 samples out of 9241 have been finished!\n","1380 samples out of 9241 have been finished!\n","1400 samples out of 9241 have been finished!\n","1420 samples out of 9241 have been finished!\n","1440 samples out of 9241 have been finished!\n","1460 samples out of 9241 have been finished!\n","1480 samples out of 9241 have been finished!\n","1500 samples out of 9241 have been finished!\n","1520 samples out of 9241 have been finished!\n","1540 samples out of 9241 have been finished!\n","1560 samples out of 9241 have been finished!\n","1580 samples out of 9241 have been finished!\n","1600 samples out of 9241 have been finished!\n","1620 samples out of 9241 have been finished!\n","1640 samples out of 9241 have been finished!\n","1660 samples out of 9241 have been finished!\n","1680 samples out of 9241 have been finished!\n","1700 samples out of 9241 have been finished!\n","1720 samples out of 9241 have been finished!\n","1740 samples out of 9241 have been finished!\n","1760 samples out of 9241 have been finished!\n","1780 samples out of 9241 have been finished!\n","1800 samples out of 9241 have been finished!\n","1820 samples out of 9241 have been finished!\n","1840 samples out of 9241 have been finished!\n","1860 samples out of 9241 have been finished!\n","1880 samples out of 9241 have been finished!\n","1900 samples out of 9241 have been finished!\n","1920 samples out of 9241 have been finished!\n","1940 samples out of 9241 have been finished!\n","1960 samples out of 9241 have been finished!\n","1980 samples out of 9241 have been finished!\n","2000 samples out of 9241 have been finished!\n","2020 samples out of 9241 have been finished!\n","2040 samples out of 9241 have been finished!\n","2060 samples out of 9241 have been finished!\n","2080 samples out of 9241 have been finished!\n","2100 samples out of 9241 have been finished!\n","2120 samples out of 9241 have been finished!\n","2140 samples out of 9241 have been finished!\n","2160 samples out of 9241 have been finished!\n","2180 samples out of 9241 have been finished!\n","2200 samples out of 9241 have been finished!\n","2220 samples out of 9241 have been finished!\n","2240 samples out of 9241 have been finished!\n","2260 samples out of 9241 have been finished!\n","2280 samples out of 9241 have been finished!\n","2300 samples out of 9241 have been finished!\n","2320 samples out of 9241 have been finished!\n","2340 samples out of 9241 have been finished!\n","2360 samples out of 9241 have been finished!\n","2380 samples out of 9241 have been finished!\n","2400 samples out of 9241 have been finished!\n","2420 samples out of 9241 have been finished!\n","2440 samples out of 9241 have been finished!\n","2460 samples out of 9241 have been finished!\n","2480 samples out of 9241 have been finished!\n","2500 samples out of 9241 have been finished!\n","2520 samples out of 9241 have been finished!\n","2540 samples out of 9241 have been finished!\n","2560 samples out of 9241 have been finished!\n","2580 samples out of 9241 have been finished!\n","2600 samples out of 9241 have been finished!\n","2620 samples out of 9241 have been finished!\n","2640 samples out of 9241 have been finished!\n","2660 samples out of 9241 have been finished!\n","2680 samples out of 9241 have been finished!\n","2700 samples out of 9241 have been finished!\n","2720 samples out of 9241 have been finished!\n","2740 samples out of 9241 have been finished!\n","2760 samples out of 9241 have been finished!\n","2780 samples out of 9241 have been finished!\n","2800 samples out of 9241 have been finished!\n","2820 samples out of 9241 have been finished!\n","2840 samples out of 9241 have been finished!\n","2860 samples out of 9241 have been finished!\n","2880 samples out of 9241 have been finished!\n","2900 samples out of 9241 have been finished!\n","2920 samples out of 9241 have been finished!\n","2940 samples out of 9241 have been finished!\n","2960 samples out of 9241 have been finished!\n","2980 samples out of 9241 have been finished!\n","3000 samples out of 9241 have been finished!\n","3020 samples out of 9241 have been finished!\n","3040 samples out of 9241 have been finished!\n","3060 samples out of 9241 have been finished!\n","3080 samples out of 9241 have been finished!\n","3100 samples out of 9241 have been finished!\n","3120 samples out of 9241 have been finished!\n","3140 samples out of 9241 have been finished!\n","3160 samples out of 9241 have been finished!\n","3180 samples out of 9241 have been finished!\n","3200 samples out of 9241 have been finished!\n","3220 samples out of 9241 have been finished!\n","3240 samples out of 9241 have been finished!\n","3260 samples out of 9241 have been finished!\n","3280 samples out of 9241 have been finished!\n","3300 samples out of 9241 have been finished!\n","3320 samples out of 9241 have been finished!\n","3340 samples out of 9241 have been finished!\n","3360 samples out of 9241 have been finished!\n","3380 samples out of 9241 have been finished!\n","3400 samples out of 9241 have been finished!\n","3420 samples out of 9241 have been finished!\n","3440 samples out of 9241 have been finished!\n","3460 samples out of 9241 have been finished!\n","3480 samples out of 9241 have been finished!\n","3500 samples out of 9241 have been finished!\n","3520 samples out of 9241 have been finished!\n","3540 samples out of 9241 have been finished!\n","3560 samples out of 9241 have been finished!\n","3580 samples out of 9241 have been finished!\n","3600 samples out of 9241 have been finished!\n","3620 samples out of 9241 have been finished!\n","3640 samples out of 9241 have been finished!\n","3660 samples out of 9241 have been finished!\n","3680 samples out of 9241 have been finished!\n","3700 samples out of 9241 have been finished!\n","3720 samples out of 9241 have been finished!\n","3740 samples out of 9241 have been finished!\n","3760 samples out of 9241 have been finished!\n","3780 samples out of 9241 have been finished!\n","3800 samples out of 9241 have been finished!\n","3820 samples out of 9241 have been finished!\n","3840 samples out of 9241 have been finished!\n","3860 samples out of 9241 have been finished!\n","3880 samples out of 9241 have been finished!\n","3900 samples out of 9241 have been finished!\n","3920 samples out of 9241 have been finished!\n","3940 samples out of 9241 have been finished!\n","3960 samples out of 9241 have been finished!\n","3980 samples out of 9241 have been finished!\n","4000 samples out of 9241 have been finished!\n","4020 samples out of 9241 have been finished!\n","4040 samples out of 9241 have been finished!\n","4060 samples out of 9241 have been finished!\n","4080 samples out of 9241 have been finished!\n","4100 samples out of 9241 have been finished!\n","4120 samples out of 9241 have been finished!\n","4140 samples out of 9241 have been finished!\n","4160 samples out of 9241 have been finished!\n","4180 samples out of 9241 have been finished!\n","4200 samples out of 9241 have been finished!\n","4220 samples out of 9241 have been finished!\n","4240 samples out of 9241 have been finished!\n","4260 samples out of 9241 have been finished!\n","4280 samples out of 9241 have been finished!\n","4300 samples out of 9241 have been finished!\n","4320 samples out of 9241 have been finished!\n","4340 samples out of 9241 have been finished!\n","4360 samples out of 9241 have been finished!\n","4380 samples out of 9241 have been finished!\n","4400 samples out of 9241 have been finished!\n","4420 samples out of 9241 have been finished!\n","4440 samples out of 9241 have been finished!\n","4460 samples out of 9241 have been finished!\n","4480 samples out of 9241 have been finished!\n","4500 samples out of 9241 have been finished!\n","4520 samples out of 9241 have been finished!\n","4540 samples out of 9241 have been finished!\n","4560 samples out of 9241 have been finished!\n","4580 samples out of 9241 have been finished!\n","4600 samples out of 9241 have been finished!\n","4620 samples out of 9241 have been finished!\n","4640 samples out of 9241 have been finished!\n","4660 samples out of 9241 have been finished!\n","4680 samples out of 9241 have been finished!\n","4700 samples out of 9241 have been finished!\n","4720 samples out of 9241 have been finished!\n","4740 samples out of 9241 have been finished!\n","4760 samples out of 9241 have been finished!\n","4780 samples out of 9241 have been finished!\n","4800 samples out of 9241 have been finished!\n","4820 samples out of 9241 have been finished!\n","4840 samples out of 9241 have been finished!\n","4860 samples out of 9241 have been finished!\n","4880 samples out of 9241 have been finished!\n","4900 samples out of 9241 have been finished!\n","4920 samples out of 9241 have been finished!\n","4940 samples out of 9241 have been finished!\n","4960 samples out of 9241 have been finished!\n","4980 samples out of 9241 have been finished!\n","5000 samples out of 9241 have been finished!\n","5020 samples out of 9241 have been finished!\n","5040 samples out of 9241 have been finished!\n","5060 samples out of 9241 have been finished!\n","5080 samples out of 9241 have been finished!\n","5100 samples out of 9241 have been finished!\n","5120 samples out of 9241 have been finished!\n","5140 samples out of 9241 have been finished!\n","5160 samples out of 9241 have been finished!\n","5180 samples out of 9241 have been finished!\n","5200 samples out of 9241 have been finished!\n","5220 samples out of 9241 have been finished!\n","5240 samples out of 9241 have been finished!\n","5260 samples out of 9241 have been finished!\n","5280 samples out of 9241 have been finished!\n","5300 samples out of 9241 have been finished!\n","5320 samples out of 9241 have been finished!\n","5340 samples out of 9241 have been finished!\n","5360 samples out of 9241 have been finished!\n","5380 samples out of 9241 have been finished!\n","5400 samples out of 9241 have been finished!\n","5420 samples out of 9241 have been finished!\n","5440 samples out of 9241 have been finished!\n","5460 samples out of 9241 have been finished!\n","5480 samples out of 9241 have been finished!\n","5500 samples out of 9241 have been finished!\n","5520 samples out of 9241 have been finished!\n","5540 samples out of 9241 have been finished!\n","5560 samples out of 9241 have been finished!\n","5580 samples out of 9241 have been finished!\n","5600 samples out of 9241 have been finished!\n","5620 samples out of 9241 have been finished!\n","5640 samples out of 9241 have been finished!\n","5660 samples out of 9241 have been finished!\n","5680 samples out of 9241 have been finished!\n","5700 samples out of 9241 have been finished!\n","5720 samples out of 9241 have been finished!\n","5740 samples out of 9241 have been finished!\n","5760 samples out of 9241 have been finished!\n","5780 samples out of 9241 have been finished!\n","5800 samples out of 9241 have been finished!\n","5820 samples out of 9241 have been finished!\n","5840 samples out of 9241 have been finished!\n","5860 samples out of 9241 have been finished!\n","5880 samples out of 9241 have been finished!\n","5900 samples out of 9241 have been finished!\n","5920 samples out of 9241 have been finished!\n","5940 samples out of 9241 have been finished!\n","5960 samples out of 9241 have been finished!\n","5980 samples out of 9241 have been finished!\n","6000 samples out of 9241 have been finished!\n","6020 samples out of 9241 have been finished!\n","6040 samples out of 9241 have been finished!\n","6060 samples out of 9241 have been finished!\n","6080 samples out of 9241 have been finished!\n","6100 samples out of 9241 have been finished!\n","6120 samples out of 9241 have been finished!\n","6140 samples out of 9241 have been finished!\n","6160 samples out of 9241 have been finished!\n","6180 samples out of 9241 have been finished!\n","6200 samples out of 9241 have been finished!\n","6220 samples out of 9241 have been finished!\n","6240 samples out of 9241 have been finished!\n","6260 samples out of 9241 have been finished!\n","6280 samples out of 9241 have been finished!\n","6300 samples out of 9241 have been finished!\n","6320 samples out of 9241 have been finished!\n","6340 samples out of 9241 have been finished!\n","6360 samples out of 9241 have been finished!\n","6380 samples out of 9241 have been finished!\n","6400 samples out of 9241 have been finished!\n","6420 samples out of 9241 have been finished!\n","6440 samples out of 9241 have been finished!\n","6460 samples out of 9241 have been finished!\n","6480 samples out of 9241 have been finished!\n","6500 samples out of 9241 have been finished!\n","6520 samples out of 9241 have been finished!\n","6540 samples out of 9241 have been finished!\n","6560 samples out of 9241 have been finished!\n","6580 samples out of 9241 have been finished!\n","6600 samples out of 9241 have been finished!\n","6620 samples out of 9241 have been finished!\n","6640 samples out of 9241 have been finished!\n","6660 samples out of 9241 have been finished!\n","6680 samples out of 9241 have been finished!\n","6700 samples out of 9241 have been finished!\n","6720 samples out of 9241 have been finished!\n","6740 samples out of 9241 have been finished!\n","6760 samples out of 9241 have been finished!\n","6780 samples out of 9241 have been finished!\n","6800 samples out of 9241 have been finished!\n","6820 samples out of 9241 have been finished!\n","6840 samples out of 9241 have been finished!\n","6860 samples out of 9241 have been finished!\n","6880 samples out of 9241 have been finished!\n","6900 samples out of 9241 have been finished!\n","6920 samples out of 9241 have been finished!\n","6940 samples out of 9241 have been finished!\n","6960 samples out of 9241 have been finished!\n","6980 samples out of 9241 have been finished!\n","7000 samples out of 9241 have been finished!\n","7020 samples out of 9241 have been finished!\n","7040 samples out of 9241 have been finished!\n","7060 samples out of 9241 have been finished!\n","7080 samples out of 9241 have been finished!\n","7100 samples out of 9241 have been finished!\n","7120 samples out of 9241 have been finished!\n","7140 samples out of 9241 have been finished!\n","7160 samples out of 9241 have been finished!\n","7180 samples out of 9241 have been finished!\n","7200 samples out of 9241 have been finished!\n","7220 samples out of 9241 have been finished!\n","7240 samples out of 9241 have been finished!\n","7260 samples out of 9241 have been finished!\n","7280 samples out of 9241 have been finished!\n","7300 samples out of 9241 have been finished!\n","7320 samples out of 9241 have been finished!\n","7340 samples out of 9241 have been finished!\n","7360 samples out of 9241 have been finished!\n","7380 samples out of 9241 have been finished!\n","7400 samples out of 9241 have been finished!\n","7420 samples out of 9241 have been finished!\n","7440 samples out of 9241 have been finished!\n","7460 samples out of 9241 have been finished!\n","7480 samples out of 9241 have been finished!\n","7500 samples out of 9241 have been finished!\n","7520 samples out of 9241 have been finished!\n","7540 samples out of 9241 have been finished!\n","7560 samples out of 9241 have been finished!\n","7580 samples out of 9241 have been finished!\n","7600 samples out of 9241 have been finished!\n","7620 samples out of 9241 have been finished!\n","7640 samples out of 9241 have been finished!\n","7660 samples out of 9241 have been finished!\n","7680 samples out of 9241 have been finished!\n","7700 samples out of 9241 have been finished!\n","7720 samples out of 9241 have been finished!\n","7740 samples out of 9241 have been finished!\n","7760 samples out of 9241 have been finished!\n","7780 samples out of 9241 have been finished!\n","7800 samples out of 9241 have been finished!\n","7820 samples out of 9241 have been finished!\n","7840 samples out of 9241 have been finished!\n","7860 samples out of 9241 have been finished!\n","7880 samples out of 9241 have been finished!\n","7900 samples out of 9241 have been finished!\n","7920 samples out of 9241 have been finished!\n","7940 samples out of 9241 have been finished!\n","7960 samples out of 9241 have been finished!\n","7980 samples out of 9241 have been finished!\n","8000 samples out of 9241 have been finished!\n","8020 samples out of 9241 have been finished!\n","8040 samples out of 9241 have been finished!\n","8060 samples out of 9241 have been finished!\n","8080 samples out of 9241 have been finished!\n","8100 samples out of 9241 have been finished!\n","8120 samples out of 9241 have been finished!\n","8140 samples out of 9241 have been finished!\n","8160 samples out of 9241 have been finished!\n","8180 samples out of 9241 have been finished!\n","8200 samples out of 9241 have been finished!\n","8220 samples out of 9241 have been finished!\n","8240 samples out of 9241 have been finished!\n","8260 samples out of 9241 have been finished!\n","8280 samples out of 9241 have been finished!\n","8300 samples out of 9241 have been finished!\n","8320 samples out of 9241 have been finished!\n","8340 samples out of 9241 have been finished!\n","8360 samples out of 9241 have been finished!\n","8380 samples out of 9241 have been finished!\n","8400 samples out of 9241 have been finished!\n","8420 samples out of 9241 have been finished!\n","8440 samples out of 9241 have been finished!\n","8460 samples out of 9241 have been finished!\n","8480 samples out of 9241 have been finished!\n","8500 samples out of 9241 have been finished!\n","8520 samples out of 9241 have been finished!\n","8540 samples out of 9241 have been finished!\n","8560 samples out of 9241 have been finished!\n","8580 samples out of 9241 have been finished!\n","8600 samples out of 9241 have been finished!\n","8620 samples out of 9241 have been finished!\n","8640 samples out of 9241 have been finished!\n","8660 samples out of 9241 have been finished!\n","8680 samples out of 9241 have been finished!\n","8700 samples out of 9241 have been finished!\n","8720 samples out of 9241 have been finished!\n","8740 samples out of 9241 have been finished!\n","8760 samples out of 9241 have been finished!\n","8780 samples out of 9241 have been finished!\n","8800 samples out of 9241 have been finished!\n","8820 samples out of 9241 have been finished!\n","8840 samples out of 9241 have been finished!\n","8860 samples out of 9241 have been finished!\n","8880 samples out of 9241 have been finished!\n","8900 samples out of 9241 have been finished!\n","8920 samples out of 9241 have been finished!\n","8940 samples out of 9241 have been finished!\n","8960 samples out of 9241 have been finished!\n","8980 samples out of 9241 have been finished!\n","9000 samples out of 9241 have been finished!\n","9020 samples out of 9241 have been finished!\n","9040 samples out of 9241 have been finished!\n","9060 samples out of 9241 have been finished!\n","9080 samples out of 9241 have been finished!\n","9100 samples out of 9241 have been finished!\n","9120 samples out of 9241 have been finished!\n","9140 samples out of 9241 have been finished!\n","9160 samples out of 9241 have been finished!\n","9180 samples out of 9241 have been finished!\n","9200 samples out of 9241 have been finished!\n","9220 samples out of 9241 have been finished!\n","9240 samples out of 9241 have been finished!\n","For target model bert: original accuracy: -361.100%, adv accuracy: -804.300%, avg changed rate: 16.024%, num of queries: 93.0\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LM1qLEh2-MPf"},"source":[""],"execution_count":null,"outputs":[]}]}